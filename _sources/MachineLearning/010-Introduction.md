# Machine Learning

Categories of ML problems

Basic mathematical concepts that span machine learning

Something about gradient descent

* model cards
* model quality evaluation
* One-Shot, Few-Shot
* Transfer Learning
* Convolutional Neural Networks
* LSTM
* Support Vector Machine (SVM)
* MLM
* Gradient Boosted Trees
* repeatability
* feature stores
* experiment tracking
* Reinforcement Learning
* Active Learning
* Self-Supervision
* Yann LeCun's Deep Learning course
  * https://atcold.github.io/pytorch-Deep-Learning/

## Semi-Supervised Learning

Wikipedia: https://en.wikipedia.org/wiki/Semi-Supervised_Learning#

> Semi-supervised learning, otherwise termed weak supervision, is a branch of machine learning where noisy, limited, or imprecise sources are used to provide supervision signal for labeling large amounts of training data in a supervised learning setting.[1] This approach alleviates the burden of obtaining hand-labeled data sets, which can be costly or impractical. Instead, inexpensive weak labels are employed with the understanding that they are imperfect, but can nonetheless be used to create a strong predictive model.[2][3][4] Semi-supervised learning can therefore be seen as a reasonable middleground between supervised and unsupervised machine learning approaches.

## Generative Adversarial Network (GAN)

Wikipedia: https://en.wikipedia.org/wiki/Generative_adversarial_network

> A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014.[1] Two neural networks contest with each other in the form of a zero-sum game, where one agent's gain is another agent's loss.
Given a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of generative model for unsupervised learning, GANs have also proved useful for semi-supervised learning,[2] fully supervised learning,[3] and reinforcement learning.[4]
> The core idea of a GAN is based on the "indirect" training through the discriminator, another neural network that can tell how "realistic" the input seems, which itself is also being updated dynamically.[5] This means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.
> GANs are similar to mimicry in evolutionary biology, with an evolutionary arms race between both networks.

## Artificial General Intelligence (AGI)

Yann LeCun “A Path Towards Autonomous Machine Intelligence”
https://openreview.net/pdf?id=BZ5a1r-kVsf

